{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLRe6RGGwOheW6KHrYy2hT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A77uVBBFPAB",
        "outputId": "e09dfe7b-6036-4294-a63a-593aea349891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mediapipe-model-maker in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (1.4.0)\n",
            "Requirement already satisfied: mediapipe>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (1.25.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (4.7.0.72)\n",
            "Requirement already satisfied: tensorflow>=2.10 in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (2.11.1)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (4.9.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (0.13.0)\n",
            "Requirement already satisfied: tf-models-official==2.11.6 in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (2.11.6)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (0.29.34)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (8.4.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (2.84.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (2.2.4)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (1.5.13)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (3.7.1)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (4.7.0.72)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (1.5.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (2.0.6)\n",
            "Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (5.4.1)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (1.10.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (0.1.99)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (1.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (0.20.0)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (0.7.5)\n",
            "Requirement already satisfied: tensorflow-text~=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (2.11.0)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.11.6->mediapipe-model-maker) (1.1.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (23.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (23.3.3)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (4.7.0.72)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (3.19.6)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.4.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.6.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (3.8.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (23.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.10->mediapipe-model-maker) (0.32.0)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (8.1.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (1.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.27.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (1.13.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (4.65.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.10->mediapipe-model-maker) (0.40.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->mediapipe-model-maker) (5.12.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->mediapipe-model-maker) (3.15.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.11.6->mediapipe-model-maker) (0.21.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.11.6->mediapipe-model-maker) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.11.6->mediapipe-model-maker) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.11.6->mediapipe-model-maker) (2.11.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.11.6->mediapipe-model-maker) (4.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.11.6->mediapipe-model-maker) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.11.6->mediapipe-model-maker) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.11.6->mediapipe-model-maker) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.11.6->mediapipe-model-maker) (1.26.15)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official==2.11.6->mediapipe-model-maker) (2022.7.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->mediapipe-model-maker) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->mediapipe-model-maker) (3.4)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (1.15.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.10->mediapipe-model-maker) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.10->mediapipe-model-maker) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.10->mediapipe-model-maker) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.10->mediapipe-model-maker) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.10->mediapipe-model-maker) (2.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.11.6->mediapipe-model-maker) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.11.6->mediapipe-model-maker) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.11.6->mediapipe-model-maker) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.11.6->mediapipe-model-maker) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.11.6->mediapipe-model-maker) (3.0.9)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.11.6->mediapipe-model-maker) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.11.6->mediapipe-model-maker) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.11.6->mediapipe-model-maker) (4.9)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.11.6->mediapipe-model-maker) (2.7.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.11.6->mediapipe-model-maker) (2022.10.31)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.11.6->mediapipe-model-maker) (0.8.10)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.11.6->mediapipe-model-maker) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.11.6->mediapipe-model-maker) (4.9.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official==2.11.6->mediapipe-model-maker) (1.2.2)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons->tf-models-official==2.11.6->mediapipe-model-maker) (2.13.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->mediapipe-model-maker) (1.59.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (2.21)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.11.6->mediapipe-model-maker) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.10->mediapipe-model-maker) (1.3.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.11.6->mediapipe-model-maker) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.11.6->mediapipe-model-maker) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow>=2.10->mediapipe-model-maker) (2.1.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.11.6->mediapipe-model-maker) (1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.10->mediapipe-model-maker) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install mediapipe-model-maker"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==\"2.11.1\"\n",
        "\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd3ixK4EIExx",
        "outputId": "6c64f3e5-6eaa-4a7c-95e7-42ba973a1631"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.11.1\n",
            "Uninstalling tensorflow-2.11.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.11.1.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.11.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.11.1\n",
            "  Using cached tensorflow-2.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (3.8.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (2.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (16.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (1.25.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (23.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.1) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.1) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.1) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.1) (3.2.2)\n",
            "Installing collected packages: tensorflow\n",
            "Successfully installed tensorflow-2.11.1\n",
            "2.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# import os\n",
        "# import tensorflow as tf\n",
        "# assert tf.__version__.startswith('2')\n",
        "\n",
        "# from mediapipe_model_maker import image_classifier\n",
        "\n",
        "# import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj0Ffs-hFWIE",
        "outputId": "020e67e0-494e-43c6-f635-534cd50c8f60"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hand Recognizerモデルをインポート"
      ],
      "metadata": {
        "id": "JcD8PRewSq66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from mediapipe_model_maker import gesture_recognizer\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ngVaQJ6oSjLZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Driveのマウント"
      ],
      "metadata": {
        "id": "iSVLmZDWRueH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRhhftEqRpf5",
        "outputId": "56a15400-7e52-4524-a057-c22e38c6bc33"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データセットのダウンロード"
      ],
      "metadata": {
        "id": "4Q8WjH4SGn-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image_path = tf.keras.utils.get_file(\n",
        "#     'flower_photos.tgz',\n",
        "#     'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "#     extract=True)\n",
        "# image_path = os.path.join(os.path.dirname(image_path), 'flower_photos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii9iPgiEGmyd",
        "outputId": "a3a55f29-f03f-412f-9cc4-0cada8c8bb46"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228813984/228813984 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pathの設定\n",
        "dataset_path = \"/content/drive/MyDrive/typewriter/images/src\""
      ],
      "metadata": {
        "id": "tO5Oe0mdS35b"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ディレクトリ構造からラベルを作成\n",
        "print(dataset_path)\n",
        "labels = []\n",
        "for i in os.listdir(dataset_path):\n",
        "  if os.path.isdir(os.path.join(dataset_path, i)):\n",
        "    labels.append(i)\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weuGksCNS9wD",
        "outputId": "672c6f43-eeca-4240-c22f-058ce671eee8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/typewriter/images/src\n",
            "['l', 'a', 'e', 'p', 'none']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データセットから画像をプロット"
      ],
      "metadata": {
        "id": "mnA0mQ9rTiee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NUM_EXAMPLES = 5\n",
        "\n",
        "# for label in labels:\n",
        "#   label_dir = os.path.join(dataset_path, label)\n",
        "#   example_filenames = os.listdir(label_dir)[:NUM_EXAMPLES]\n",
        "#   fig, axs = plt.subplots(1, NUM_EXAMPLES, figsize=(10,2))\n",
        "#   for i in range(NUM_EXAMPLES):\n",
        "#     axs[i].imshow(plt.imread(os.path.join(label_dir, example_filenames[i])))\n",
        "#     axs[i].get_xaxis().set_visible(False)\n",
        "#     axs[i].get_yaxis().set_visible(False)\n",
        "#   fig.suptitle(f'Showing {NUM_EXAMPLES} examples for {label}')\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "5PizKAfWTg7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データセットのダウンロード\n"
      ],
      "metadata": {
        "id": "Mx3ZQf0_SAdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image_path = tf.keras.utils.get_file(\n",
        "#     'flower_photos.tgz',\n",
        "#     'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "#     extract=True)\n",
        "# image_path = os.path.join(os.path.dirname(image_path), 'flower_photos')"
      ],
      "metadata": {
        "id": "qtQBMhM5SEX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = gesture_recognizer.Dataset.from_folder(\n",
        "    dirname=dataset_path,\n",
        "    hparams=gesture_recognizer.HandDataPreprocessingParams()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llaQwTm6Tzhe",
        "outputId": "9224872f-6902-4af8-b5d5-6d38b4edb9a7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
            "Downloading https://storage.googleapis.com/mediapipe-assets/gesture_embedder.tar.gz to /tmp/model_maker/gesture_recognizer/gesture_embedder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BNhihY0xRtJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データセットの分割"
      ],
      "metadata": {
        "id": "hFUJTHxEG5rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data = image_classifier.Dataset.from_folder(image_path)\n",
        "# train_data, remaining_data = data.split(0.8)\n",
        "# test_data, validation_data = remaining_data.split(0.5)"
      ],
      "metadata": {
        "id": "ju3J9ErnG3rZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, rest_data = data.split(0.8)\n",
        "validation_data, test_data = rest_data.split(0.5)"
      ],
      "metadata": {
        "id": "GAnaMf7sUM3i"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 再学習のプロパティを設定"
      ],
      "metadata": {
        "id": "FaRSocizJdF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# spec = image_classifier.SupportedModels.MOBILENET_V2\n",
        "# hparams = image_classifier.HParams(export_dir=\"exported_model\")\n",
        "# options = image_classifier.ImageClassifierOptions(supported_model=spec, hparams=hparams)"
      ],
      "metadata": {
        "id": "0YuCUTmRJbsr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = gesture_recognizer.HParams(export_dir=\"exported_model\")\n",
        "options = gesture_recognizer.GestureRecognizerOptions(hparams=hparams)"
      ],
      "metadata": {
        "id": "7tSFSPuaUINL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Colab自動切断防止"
      ],
      "metadata": {
        "id": "zXxZFFzgQzUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_7HsCklPQ3fJ",
        "outputId": "507d05b8-ca66-4386-e0d5-2bfc1d6d901e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデルの再学習を実行する"
      ],
      "metadata": {
        "id": "0VlJlnnlJRNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = image_classifier.ImageClassifier.create(\n",
        "#     train_data = train_data,\n",
        "#     validation_data = validation_data,\n",
        "#     options=options,\n",
        "# )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU0OUryhJTyR",
        "outputId": "20ff98be-b7f9-4d8e-bdfd-f43d33aaaa4c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 6405      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,264,389\n",
            "Trainable params: 6,405\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "1468/1468 [==============================] - 118s 78ms/step - loss: 1.8938 - accuracy: 0.2210 - val_loss: 1.4490 - val_accuracy: 0.4305\n",
            "Epoch 2/10\n",
            "1468/1468 [==============================] - 94s 64ms/step - loss: 1.2577 - accuracy: 0.5436 - val_loss: 0.9447 - val_accuracy: 0.7330\n",
            "Epoch 3/10\n",
            "1468/1468 [==============================] - 98s 67ms/step - loss: 0.9668 - accuracy: 0.7197 - val_loss: 0.8227 - val_accuracy: 0.7929\n",
            "Epoch 4/10\n",
            "1468/1468 [==============================] - 94s 64ms/step - loss: 0.8695 - accuracy: 0.7752 - val_loss: 0.7775 - val_accuracy: 0.8065\n",
            "Epoch 5/10\n",
            "1468/1468 [==============================] - 88s 60ms/step - loss: 0.8281 - accuracy: 0.7984 - val_loss: 0.7571 - val_accuracy: 0.8256\n",
            "Epoch 6/10\n",
            "1468/1468 [==============================] - 87s 59ms/step - loss: 0.8112 - accuracy: 0.8099 - val_loss: 0.7450 - val_accuracy: 0.8392\n",
            "Epoch 7/10\n",
            "1468/1468 [==============================] - 88s 60ms/step - loss: 0.7931 - accuracy: 0.8174 - val_loss: 0.7332 - val_accuracy: 0.8474\n",
            "Epoch 8/10\n",
            "1468/1468 [==============================] - 88s 60ms/step - loss: 0.8087 - accuracy: 0.8113 - val_loss: 0.7256 - val_accuracy: 0.8501\n",
            "Epoch 9/10\n",
            "1468/1468 [==============================] - 102s 69ms/step - loss: 0.7726 - accuracy: 0.8351 - val_loss: 0.7181 - val_accuracy: 0.8556\n",
            "Epoch 10/10\n",
            "1468/1468 [==============================] - 88s 60ms/step - loss: 0.7810 - accuracy: 0.8266 - val_loss: 0.7145 - val_accuracy: 0.8556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 前回作成したモデルを削除\n",
        "!rm -rf exported_model/"
      ],
      "metadata": {
        "id": "R0X-frS5YTrH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = gesture_recognizer.GestureRecognizer.create(\n",
        "    train_data=train_data,\n",
        "    validation_data=validation_data,\n",
        "    options=options\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfM1337ZUgHD",
        "outputId": "680d766c-8410-4706-b703-d2a8e925f575"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hand_embedding (InputLayer)  [(None, 128)]            0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " custom_gesture_recognizer_o  (None, 5)                645       \n",
            " ut (Dense)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,157\n",
            "Trainable params: 901\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "None\n",
            "Resuming from exported_model/epoch_models/model-0010\n",
            "Epoch 1/10\n",
            "258/258 [==============================] - 2s 5ms/step - loss: 0.4509 - categorical_accuracy: 0.6996 - val_loss: 0.1018 - val_categorical_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.4503 - categorical_accuracy: 0.6880 - val_loss: 0.0893 - val_categorical_accuracy: 0.9692 - lr: 9.9000e-04\n",
            "Epoch 3/10\n",
            "258/258 [==============================] - 1s 6ms/step - loss: 0.4411 - categorical_accuracy: 0.6919 - val_loss: 0.0882 - val_categorical_accuracy: 0.9692 - lr: 9.8010e-04\n",
            "Epoch 4/10\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.4388 - categorical_accuracy: 0.6880 - val_loss: 0.0888 - val_categorical_accuracy: 0.9692 - lr: 9.7030e-04\n",
            "Epoch 5/10\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.4354 - categorical_accuracy: 0.7151 - val_loss: 0.0861 - val_categorical_accuracy: 0.9692 - lr: 9.6060e-04\n",
            "Epoch 6/10\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.4224 - categorical_accuracy: 0.7035 - val_loss: 0.0941 - val_categorical_accuracy: 0.9538 - lr: 9.5099e-04\n",
            "Epoch 7/10\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.4246 - categorical_accuracy: 0.7054 - val_loss: 0.0898 - val_categorical_accuracy: 0.9692 - lr: 9.4148e-04\n",
            "Epoch 8/10\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.4032 - categorical_accuracy: 0.7306 - val_loss: 0.0883 - val_categorical_accuracy: 0.9538 - lr: 9.3207e-04\n",
            "Epoch 9/10\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.4122 - categorical_accuracy: 0.7054 - val_loss: 0.0836 - val_categorical_accuracy: 0.9692 - lr: 9.2274e-04\n",
            "Epoch 10/10\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.4079 - categorical_accuracy: 0.7345 - val_loss: 0.0826 - val_categorical_accuracy: 0.9538 - lr: 9.1352e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### パフォーマンス測定"
      ],
      "metadata": {
        "id": "CX_C226YJsGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_data)\n",
        "print(f'Test loss:{loss}, Test accuracy:{acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK-0ld7VJvOr",
        "outputId": "50eefab2-f397-4ccc-9cf1-b0dbeda380d3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 28ms/step - loss: 0.1199 - categorical_accuracy: 0.9077\n",
            "Test loss:0.11989104002714157, Test accuracy:0.9076923131942749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデルのエクスポート\n",
        "\n",
        "カスタマイズされたジェスチャモデルは量子化されていない浮動小数点です。<br>\n",
        "モデルは軽量であり、**量子化によってパフォーマンスと効率のバランスを取る必要はありません。**<br>\n",
        "デフォルトのscore_thresholdingは推論中に調整できるため0.5に設定されています。\n",
        "\n",
        "ref. export_model()のdocs\n",
        "https://developers.google.com/mediapipe/api/solutions/python/mediapipe_model_maker/gesture_recognizer/GestureRecognizer#export_model"
      ],
      "metadata": {
        "id": "KZNo2yS-Jz5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.export_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K295IEHALOkW",
        "outputId": "6e69c23a-2532-4e05-84e9-d54e28713bb7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing files at /tmp/model_maker/gesture_recognizer/gesture_embedder.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/canned_gesture_classifier.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls exported_model\n",
        "# files.download('exported_model/model.tflite')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "ZMQaE5B0LRhF",
        "outputId": "65c67b56-13b6-4786-f96a-ce8e53c80966"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_weights.data-00000-of-00001\tepoch_models\t\t metadata.json\n",
            "best_model_weights.index\t\tgesture_recognizer.task\n",
            "checkpoint\t\t\t\tlogs\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e79cf5ef0e88>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls exported_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exported_model/model.tflite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    220\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: exported_model/model.tflite"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls exported_model\n",
        "files.download('/tmp/model_maker/gesture_recognizer/canned_gesture_classifier.tflite')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Epd85mp9ZDyM",
        "outputId": "13617a5f-2827-4bb2-ea5b-8c9ae8c77806"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_weights.data-00000-of-00001\tepoch_models\t\t metadata.json\n",
            "best_model_weights.index\t\tgesture_recognizer.task\n",
            "checkpoint\t\t\t\tlogs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_146ec9e4-5d24-41f0-a73b-0bef48944860\", \"canned_gesture_classifier.tflite\", 6928)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデルのチューニング\n",
        "ref. https://developers.google.com/mediapipe/solutions/vision/image_classifier/customize#retraining_parameters"
      ],
      "metadata": {
        "id": "LRkWqlgPLTzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### On-device (モバイル向け) チューニング\n",
        "ref. https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer/customize#run_the_model_on-device"
      ],
      "metadata": {
        "id": "8Q7Tqnb0cj6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = gesture_recognizer.HParams(learning_rate=0.003, export_dir=\"exported_model_2\")\n",
        "model_options = gesture_recognizer.ModelOptions(dropout_rate=0.2)\n",
        "options = gesture_recognizer.GestureRecognizerOptions(model_options=model_options, hparams=hparams)"
      ],
      "metadata": {
        "id": "37FuPfFNbL_3"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = gesture_recognizer.GestureRecognizer.create(\n",
        "    train_data=train_data,\n",
        "    validation_data=validation_data,\n",
        "    options=options\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il4TNgCELWAg",
        "outputId": "9af017aa-a89e-4bc4-e7e9-0d0752e468aa"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hand_embedding (InputLayer)  [(None, 128)]            0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_4 (ReLU)              (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " custom_gesture_recognizer_o  (None, 5)                645       \n",
            " ut (Dense)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,157\n",
            "Trainable params: 901\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "None\n",
            "Resuming from exported_model_2/epoch_models/model-0010\n",
            "Epoch 1/10\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.5186 - categorical_accuracy: 0.6415 - val_loss: 0.1032 - val_categorical_accuracy: 0.9538 - lr: 0.0030\n",
            "Epoch 2/10\n",
            "258/258 [==============================] - 2s 7ms/step - loss: 0.4871 - categorical_accuracy: 0.6279 - val_loss: 0.0999 - val_categorical_accuracy: 0.8923 - lr: 0.0030\n",
            "Epoch 3/10\n",
            "258/258 [==============================] - 2s 8ms/step - loss: 0.4741 - categorical_accuracy: 0.6802 - val_loss: 0.0873 - val_categorical_accuracy: 0.9538 - lr: 0.0029\n",
            "Epoch 4/10\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.4797 - categorical_accuracy: 0.6667 - val_loss: 0.0995 - val_categorical_accuracy: 0.9231 - lr: 0.0029\n",
            "Epoch 5/10\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.5066 - categorical_accuracy: 0.6395 - val_loss: 0.1171 - val_categorical_accuracy: 0.8923 - lr: 0.0029\n",
            "Epoch 6/10\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.4728 - categorical_accuracy: 0.6802 - val_loss: 0.0986 - val_categorical_accuracy: 0.9385 - lr: 0.0029\n",
            "Epoch 7/10\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.4663 - categorical_accuracy: 0.6550 - val_loss: 0.1023 - val_categorical_accuracy: 0.9231 - lr: 0.0028\n",
            "Epoch 8/10\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.4859 - categorical_accuracy: 0.6531 - val_loss: 0.0993 - val_categorical_accuracy: 0.9231 - lr: 0.0028\n",
            "Epoch 9/10\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.5077 - categorical_accuracy: 0.6609 - val_loss: 0.0833 - val_categorical_accuracy: 0.9538 - lr: 0.0028\n",
            "Epoch 10/10\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.4810 - categorical_accuracy: 0.6667 - val_loss: 0.0923 - val_categorical_accuracy: 0.9385 - lr: 0.0027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model_2.evaluate(test_data)\n",
        "print(f'Test loss:{loss}, Test accuracy:{acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2MiA5P3Lhiu",
        "outputId": "5759bf0f-2fb4-4d12-b7ff-cea54e5775ca"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 25ms/step - loss: 0.1177 - categorical_accuracy: 0.9077\n",
            "Test loss:0.11769494414329529, Test accuracy:0.892307698726654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### チューニングしたモデルのエクスポート"
      ],
      "metadata": {
        "id": "9mKGIejggLjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.export_model()\n",
        "!ls exported_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ3NqqDGgRIF",
        "outputId": "4b0e3fdd-cd23-4e0f-a928-552a4f7a24e6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing files at /tmp/model_maker/gesture_recognizer/gesture_embedder.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/canned_gesture_classifier.tflite\n",
            "best_model_weights.data-00000-of-00001\tepoch_models\t\t metadata.json\n",
            "best_model_weights.index\t\tgesture_recognizer.task\n",
            "checkpoint\t\t\t\tlogs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### チューニングしたモデルのダウンロード"
      ],
      "metadata": {
        "id": "RMpvig0jerdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /tmp/model_maker/gesture_recognizer/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xodnKJhXe8TO",
        "outputId": "5c701e43-81d1-4804-a146-ff2be1a6384c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "canned_gesture_classifier.tflite  hand_landmark_full.tflite\n",
            "gesture_embedder\t\t  palm_detection_full.tflite\n",
            "gesture_embedder.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('exported_model/gesture_recognizer.task')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7IdzqGGmeuTv",
        "outputId": "171bd706-1437-461b-aaeb-7bfd84d25569"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d66a750e-0b90-4f37-bc5f-2c64b6f150e4\", \"gesture_recognizer.task\", 8461395)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデルの量子化 (GestureRecognizerでは不要)"
      ],
      "metadata": {
        "id": "oAm88si4LlUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mediapipe_model_maker import quantization"
      ],
      "metadata": {
        "id": "s4Sm41nJLm5E"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantization_config = quantization.QuantizationConfig.for_int8(train_data)"
      ],
      "metadata": {
        "id": "rfNCyC0ALpb3"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.export_model(model_name=\"gesture_model_int8.tflite\", quantization_config=quantization_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "WRaiYGlNLqAW",
        "outputId": "3d7d395f-42af-45c0-d3ae-a8c95a7d10f9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-77b258875d04>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gesture_model_int8.tflite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantization_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: GestureRecognizer.export_model() got an unexpected keyword argument 'quantization_config'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 量子化した新しいモデルの入手"
      ],
      "metadata": {
        "id": "Ef5t0mD8LyTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh exported_model"
      ],
      "metadata": {
        "id": "VWyR60a4L1iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 以上"
      ],
      "metadata": {
        "id": "PX0D3cvBg0Sk"
      }
    }
  ]
}